import pandas as pd
import chardet
import re
import os

def detect_encoding(file_path):
    """íŒŒì¼ì˜ ì¼ë¶€ë¥¼ ì½ì–´ ì¸ì½”ë”©ì„ ìµœëŒ€í•œ ì •í™•í•˜ê²Œ ê°ì§€"""
    with open(file_path, 'rb') as f:
        rawdata = f.read(50000)  # ê°ì§€ ì •í™•ë„ë¥¼ ìœ„í•´ ì½ê¸° ë²”ìœ„ í™•ëŒ€
    result = chardet.detect(rawdata)
    encoding = result['encoding']
    confidence = result['confidence']
    return encoding, confidence

def fix_broken_korean(text):
    """
    ì´ë¯¸ ê¹¨ì§„ ìƒíƒœë¡œ ë¡œë“œëœ ë¬¸ìì—´ì„ ë³µêµ¬ ì‹œë„ (ftfy ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—­í• ì„ ì¼ë¶€ ìˆ˜í–‰)
    ì¸ì½”ë”© ê¼¬ì„(Mojibake) í˜„ìƒì„ í•´ê²°í•˜ê¸° ìœ„í•œ ë¡œì§
    """
    if pd.isna(text) or not isinstance(text, str): return text
    
    try:
        # UTF-8 ë°ì´í„°ë¥¼ ISO-8859-1ë¡œ ì˜ëª» ì½ì—ˆì„ ê²½ìš° ë‹¤ì‹œ ë˜ëŒë¦¼
        return text.encode('latin-1').decode('utf-8')
    except (UnicodeEncodeError, UnicodeDecodeError):
        try:
            # CP949 ë°ì´í„°ë¥¼ latin-1ë¡œ ì˜ëª» ì½ì—ˆì„ ê²½ìš°
            return text.encode('latin-1').decode('cp949')
        except:
            return text

def preprocess_csv(file_path):
    encoding, confidence = detect_encoding(file_path)
    print(f"ğŸ” ê°ì§€ëœ ì¸ì½”ë”©: {encoding} (ì‹ ë¢°ë„: {confidence:.2f})")
    
    # 1. ì¼ì°¨ì ìœ¼ë¡œ ê°ì§€ëœ ì¸ì½”ë”©ìœ¼ë¡œ ë¡œë“œ ì‹œë„
    try:
        # ì¸ì½”ë”© ì—ëŸ¬ ë°œìƒ ì‹œ ì‚­ì œí•˜ì§€ ì•Šê³  'replace'í•˜ì—¬ ìµœëŒ€í•œ ì½ì–´ì˜´
        df = pd.read_csv(file_path, encoding=encoding, on_bad_lines='skip')
    except:
        # ì‹¤íŒ¨ ì‹œ í•œêµ­ì–´ ìœˆë„ìš° í‘œì¤€ì¸ cp949 ì‹œë„
        df = pd.read_csv(file_path, encoding='cp949', encoding_errors='replace')

    raw_count = len(df)
    
    # 2. ë¬¸ìì—´ ì»¬ëŸ¼ ë³µêµ¬ ë¡œì§ ì ìš©
    str_cols = df.select_dtypes(include=['object', 'string']).columns
    for col in str_cols:
        # ì œê±°(re.sub) ëŒ€ì‹  ë³µêµ¬(fix_broken_korean) ì ìš©
        df[col] = df[col].apply(fix_broken_korean)
        
        # ë³µêµ¬ í›„ì—ë„ ë‚¨ì€ ë¶ˆí•„ìš”í•œ íŠ¹ìˆ˜ ì œì–´ ë¬¸ìë§Œ ìµœì†Œí•œìœ¼ë¡œ ì •ë¦¬
        df[col] = df[col].apply(lambda x: re.sub(r'[\x00-\x08\x0b\x0c\x0e-\x1f\x7f]', '', str(x)) if pd.notna(x) else x)

    # 3. [ê²€ì¦] ë³µêµ¬ í›„ í•œê¸€ ë¹„ì¤‘ ë¶„ì„ (ì‚­ì œ ê¸°ì¤€ ì™„í™”)
    def korean_ratio(text):
        if not text or pd.isna(text): return 0
        ko_count = len(re.findall(r'[ê°€-í£]', str(text)))
        return ko_count / len(str(text)) if len(str(text)) > 0 else 0

    # ë³µêµ¬ê°€ ë¶ˆê°€ëŠ¥í•œ ì™„ì „í•œ ì“°ë ˆê¸° ë°ì´í„°ë§Œ ìµœì†Œí•œìœ¼ë¡œ í•„í„°ë§ (ë¹„ì¤‘ 50% -> 10%ë¡œ ì™„í™”)
    # ë³µêµ¬ ë¡œì§ì„ ê±°ì³¤ìœ¼ë¯€ë¡œ ì›¬ë§Œí•œ ë°ì´í„°ëŠ” ì‚´ì•„ë‚¨ìŠµë‹ˆë‹¤.
    df = df[df['title'].apply(korean_ratio) > 0.1] 
    
    clean_count = len(df)

    print("-" * 40)
    print(f"ğŸ“Š ë³µêµ¬ ë° ì „ì²˜ë¦¬ ë¦¬í¬íŠ¸")
    print(f"  - ì›ë³¸ ë°ì´í„°: {raw_count:,}ê±´")
    print(f"  - ë³µêµ¬ ë° ìœ ì§€ ë°ì´í„°: {clean_count:,}ê±´")
    print(f"  - ì‚­ì œëœ ë¶ˆë³µêµ¬ ë°ì´í„°: {raw_count - clean_count:,}ê±´")
    print("-" * 40)

    return df

if __name__ == "__main__":
    # ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ
    input_path = "data/scraped/raw_incheon_incheon.csv"
    output_path = "data/scraped/raw_incheon_incheon.csv" 
    
    if os.path.exists(input_path):
        result_df = preprocess_csv(input_path)
        
        try:
            # ì €ì¥ ì‹œì—ëŠ” ê°€ì¥ ë²”ìš©ì ì¸ utf-8-sig (ì—‘ì…€ í˜¸í™˜) ì‚¬ìš©
            result_df.to_csv(output_path, index=False, encoding='utf-8-sig')
            print(f"âœ… ë³µêµ¬ ì™„ë£Œëœ ê²°ê³¼ê°€ '{output_path}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        except PermissionError:
            print(f"âŒ ì—ëŸ¬: íŒŒì¼ì´ ì—´ë ¤ ìˆìŠµë‹ˆë‹¤. ì¢…ë£Œ í›„ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.")