"""
í¬ë¡¤ëŸ¬ ë§¤ë‹ˆì €
ì—¬ëŸ¬ ì§€ì—­ í¬ë¡¤ëŸ¬ë¥¼ í†µí•© ê´€ë¦¬
"""

import pandas as pd
from typing import List, Dict
import logging

# ì§€ì—­ë³„ í¬ë¡¤ëŸ¬ ì„í¬íŠ¸
from regional.seoul.seoul_shinmun import SeoulShinmunCrawler
from regional.gyeonggi.gyeonggi_ilbo import GyeonggiIlboCrawler
from regional.gangwon.gangwon_domin_ilbo import GangwonDominIlboCrawler

# ë°ì´í„°ë² ì´ìŠ¤ ë° í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
from database_manager import DatabaseManager
from text_file_saver import TextFileSaver

logger = logging.getLogger('CrawlerManager')


class CrawlerManager:
    """ì§€ì—­ë³„ í¬ë¡¤ëŸ¬ë¥¼ í†µí•© ê´€ë¦¬"""

    def __init__(self, use_database: bool = True, save_text_files: bool = True):
        """
        Args:
            use_database: ë°ì´í„°ë² ì´ìŠ¤ ì‚¬ìš© ì—¬ë¶€
            save_text_files: í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì—¬ë¶€
        """
        self.crawlers = []
        self.all_articles = []
        self.region_stats = {}

        # ë°ì´í„°ë² ì´ìŠ¤ ë§¤ë‹ˆì €
        self.use_database = use_database
        if use_database:
            self.db_manager = DatabaseManager()

        # í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
        self.save_text_files = save_text_files
        if save_text_files:
            self.text_saver = TextFileSaver()

    def register_crawler(self, crawler):
        """í¬ë¡¤ëŸ¬ ë“±ë¡"""
        self.crawlers.append(crawler)
        logger.info(f"âœ“ {crawler.newspaper_name} í¬ë¡¤ëŸ¬ ë“±ë¡")

    def register_all_crawlers(self):
        """ëª¨ë“  ì§€ì—­ í¬ë¡¤ëŸ¬ ê¸°ë³¸ ë“±ë¡"""
        crawlers_list = [
            SeoulShinmunCrawler(),
            GyeonggiIlboCrawler(),
            GangwonDominIlboCrawler(),
        ]

        for crawler in crawlers_list:
            self.register_crawler(crawler)

    def run_by_region(self, region: str, max_articles: int = 50) -> List[Dict]:
        """
        íŠ¹ì • ì§€ì—­ì˜ í¬ë¡¤ëŸ¬ë§Œ ì‹¤í–‰

        Args:
            region: ì§€ì—­ëª… (ì˜ˆ: 'ì„œìš¸', 'ê²½ê¸°ë„', 'ê°•ì›ë„')
            max_articles: ì‹ ë¬¸ì‚¬ë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜
        """
        target_crawlers = [c for c in self.crawlers if c.region == region]

        logger.info(f"\n{'=' * 60}")
        logger.info(f"ğŸ•·ï¸  [{region}] í¬ë¡¤ë§ ì‹œì‘ ({len(target_crawlers)}ê°œ ì‹ ë¬¸)")
        logger.info(f"{'=' * 60}\n")

        for crawler in target_crawlers:
            articles = crawler.crawl(max_articles=max_articles)
            self.all_articles.extend(articles)

        return self.all_articles

    def run_all_crawlers(self, max_articles: int = 50) -> List[Dict]:
        """
        ëª¨ë“  ì§€ì—­ì˜ ëª¨ë“  í¬ë¡¤ëŸ¬ ì‹¤í–‰

        Args:
            max_articles: ì‹ ë¬¸ì‚¬ë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜
        """
        logger.info(f"\n\n{'=' * 70}")
        logger.info("ğŸ•·ï¸  [ì „ì²´] ì§€ì—­ë³„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹œì‘")
        logger.info(f"    - í¬ë¡¤ëŸ¬ ìˆ˜: {len(self.crawlers)}ê°œ")
        logger.info(f"    - ì‹ ë¬¸ì‚¬ë‹¹ ê¸°ì‚¬ ìˆ˜: {max_articles}ê°œ")
        logger.info(f"{'=' * 70}\n")

        for idx, crawler in enumerate(self.crawlers, 1):
            logger.info(f"[{idx}/{len(self.crawlers)}] {crawler.newspaper_name}({crawler.region})")
            articles = crawler.crawl(max_articles=max_articles)
            self.all_articles.extend(articles)

            # ì§€ì—­ë³„ í†µê³„
            self.region_stats[crawler.region] = self.region_stats.get(crawler.region, 0) + len(articles)

        logger.info(f"\n{'=' * 70}")
        logger.info(f"âœ“ ì „ì²´ í¬ë¡¤ë§ ì™„ë£Œ: {len(self.all_articles)}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘")
        logger.info(f"{'=' * 70}\n")

        return self.all_articles

    def to_dataframe(self) -> pd.DataFrame:
        """ëª¨ë“  ê¸°ì‚¬ë¥¼ DataFrameìœ¼ë¡œ ë°˜í™˜"""
        if not self.all_articles:
            return pd.DataFrame()
        return pd.DataFrame(self.all_articles).sort_values('date', ascending=False).reset_index(drop=True)

    def save_to_csv(self, filename: str = '../data/regional_news.csv'):
        """CSV íŒŒì¼ë¡œ ì €ì¥"""
        df = self.to_dataframe()
        if df.empty:
            logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        df.to_csv(filename, index=False, encoding='utf-8-sig')
        logger.info(f"\nâœ“ CSV íŒŒì¼ ì €ì¥: {filename}")
        logger.info(f"  - ì „ì²´ ê¸°ì‚¬: {len(df)}ê°œ")
        logger.info(f"  - ìˆ˜ì§‘ ì§€ì—­: {sorted(df['region'].unique().tolist())}")
        logger.info(f"  - ìˆ˜ì§‘ ì‹ ë¬¸: {sorted(df['source'].unique().tolist())}")

    def save_to_database(self):
        """ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥"""
        if not self.use_database:
            logger.warning("ë°ì´í„°ë² ì´ìŠ¤ê°€ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        if not self.all_articles:
            logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        logger.info(f"\n{'=' * 70}")
        logger.info("ğŸ’¾ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘...")
        logger.info(f"{'=' * 70}")

        # ê¸°ì‚¬ ì €ì¥
        inserted = self.db_manager.insert_articles(self.all_articles)

        # ì§€ì—­ë³„ í†µê³„ ì—…ë°ì´íŠ¸
        for region, count in self.region_stats.items():
            newspapers = [a['newspaper'] for a in self.all_articles if a['region'] == region]
            for newspaper in set(newspapers):
                news_count = sum(1 for a in self.all_articles if a['region'] == region and a['newspaper'] == newspaper)
                self.db_manager.update_region_stats(region, newspaper, news_count)

        logger.info(f"âœ“ {inserted}ê°œ ê¸°ì‚¬ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ")

        # í†µê³„ ì¶œë ¥
        self.db_manager.print_stats()

    def save_as_text_files(self):
        """ì›ë³¸ ë‰´ìŠ¤ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥"""
        if not self.save_text_files:
            logger.warning("í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ì´ í™œì„±í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return

        if not self.all_articles:
            logger.warning("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        logger.info(f"\n{'=' * 70}")
        logger.info("ğŸ“„ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥ ì¤‘...")
        logger.info(f"{'=' * 70}")

        # ê°œë³„ í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
        saved_count = self.text_saver.save_articles(self.all_articles)

        # ì¸ë±ìŠ¤ íŒŒì¼ ìƒì„±
        self.text_saver.create_index_file(self.all_articles)

        logger.info(f"âœ“ {saved_count}ê°œ ê¸°ì‚¬ë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥ ì™„ë£Œ")

    def save_all(self, csv_filename: str = '../../data/regional_news.csv'):
        """
        ëª¨ë“  í¬ë§·ìœ¼ë¡œ ì €ì¥ (CSV + ë°ì´í„°ë² ì´ìŠ¤ + í…ìŠ¤íŠ¸ íŒŒì¼)

        Args:
            csv_filename: CSV íŒŒì¼ ê²½ë¡œ
        """
        logger.info(f"\n{'=' * 70}")
        logger.info("ğŸ’¾ ë°ì´í„° ì €ì¥ ì‹œì‘")
        logger.info(f"{'=' * 70}\n")

        # 1. CSV ì €ì¥
        self.save_to_csv(csv_filename)

        # 2. ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
        if self.use_database:
            self.save_to_database()

        # 3. í…ìŠ¤íŠ¸ íŒŒì¼ ì €ì¥
        if self.save_text_files:
            self.save_as_text_files()

        logger.info(f"\n{'=' * 70}")
        logger.info("âœ… ëª¨ë“  ë°ì´í„° ì €ì¥ ì™„ë£Œ!")
        logger.info(f"{'=' * 70}\n")

    def print_stats(self):
        """ìˆ˜ì§‘ í†µê³„ ì¶œë ¥"""
        df = self.to_dataframe()

        if df.empty:
            logger.warning("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        logger.info(f"\n{'=' * 70}")
        logger.info("ğŸ“Š ìˆ˜ì§‘ í†µê³„")
        logger.info(f"{'=' * 70}")

        # ì§€ì—­ë³„ í†µê³„
        logger.info("\nğŸ“ ì§€ì—­ë³„ ê¸°ì‚¬ ìˆ˜:")
        region_stats = df.groupby('region').size().sort_values(ascending=False)
        for region, count in region_stats.items():
            logger.info(f"  {region}: {count}ê°œ")

        # ì‹ ë¬¸ì‚¬ë³„ í†µê³„
        logger.info("\nğŸ“° ì‹ ë¬¸ì‚¬ë³„ ê¸°ì‚¬ ìˆ˜:")
        newspaper_stats = df.groupby('source').size().sort_values(ascending=False)
        for source, count in newspaper_stats.items():
            logger.info(f"  {source}: {count}ê°œ")

        logger.info(f"\n{'=' * 70}\n")
