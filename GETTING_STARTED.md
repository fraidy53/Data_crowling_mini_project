# ğŸ•·ï¸ ì§€ì—­ ê²½ì œ ë‰´ìŠ¤ í¬ë¡¤ëŸ¬ ì‹œì‘ ê°€ì´ë“œ

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Project_mini/
â”œâ”€â”€ .github/
â”‚   â””â”€â”€ copilot-instructions.md
â”œâ”€â”€ src/
â”‚   â””â”€â”€ crawlers/
â”‚       â”œâ”€â”€ base_crawler.py              # ë¶€ëª¨ í´ë˜ìŠ¤ (ì¶”ìƒí™”)
â”‚       â”œâ”€â”€ crawler_manager.py           # í†µí•© ê´€ë¦¬ì
â”‚       â”œâ”€â”€ run_crawlers.py              # ë©”ì¸ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸
â”‚       â””â”€â”€ regional/
â”‚           â”œâ”€â”€ seoul/
â”‚           â”‚   â””â”€â”€ seoul_shinmun.py     # ì„œìš¸ì‹ ë¬¸ í¬ë¡¤ëŸ¬
â”‚           â”œâ”€â”€ gyeonggi/
â”‚           â”‚   â””â”€â”€ gyeonggi_ilbo.py     # ê²½ê¸°ì¼ë³´ í¬ë¡¤ëŸ¬
â”‚           â””â”€â”€ gangwon/
â”‚               â””â”€â”€ gangwon_domin_ilbo.py # ê°•ì›ë„ë¯¼ì¼ë³´ í¬ë¡¤ëŸ¬
â”œâ”€â”€ data/
â”‚   â””â”€â”€ regional_news.csv                # ì¶œë ¥ íŒŒì¼ (ìƒì„±ë¨)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ test_crawler.py
â””â”€â”€ README.md
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1. ì˜ì¡´ì„± ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. í…ŒìŠ¤íŠ¸ ì‹¤í–‰ (ê° ì‹ ë¬¸ì‚¬ 5ê°œ ê¸°ì‚¬)

```bash
python test_crawler.py
```

### 3. ì „ì²´ í¬ë¡¤ë§ ì‹¤í–‰

```bash
# ëª¨ë“  ì§€ì—­ í¬ë¡¤ë§ (ê° ì‹ ë¬¸ì‚¬ 50ê°œ ê¸°ì‚¬)
cd src/crawlers
python run_crawlers.py --mode all --articles 50
```

### 4. íŠ¹ì • ì§€ì—­ë§Œ í¬ë¡¤ë§

```bash
# ì„œìš¸ë§Œ í¬ë¡¤ë§
python run_crawlers.py --mode region --region ì„œìš¸ --articles 30

# ê²½ê¸°ë„ë§Œ í¬ë¡¤ë§
python run_crawlers.py --mode region --region ê²½ê¸°ë„ --articles 30

# ê°•ì›ë„ë§Œ í¬ë¡¤ë§
python run_crawlers.py --mode region --region ê°•ì›ë„ --articles 30
```

## ğŸ“Š ì¶œë ¥ íŒŒì¼

í¬ë¡¤ë§ëœ ë°ì´í„°ëŠ” `data/regional_news.csv`ì— ì €ì¥ë©ë‹ˆë‹¤.

**CSV êµ¬ì¡°:**
- title: ê¸°ì‚¬ ì œëª©
- content: ê¸°ì‚¬ ë³¸ë¬¸
- url: ê¸°ì‚¬ URL
- date: ë°œí–‰ ë‚ ì§œ
- writer: ê¸°ìëª…
- source: ì‹ ë¬¸ì‚¬ëª…
- newspaper: ì‹ ë¬¸ì‚¬ëª… (ë™ì¼)
- region: ì§€ì—­ëª…
- collected_at: ìˆ˜ì§‘ ì‹œê°„

## ğŸ”§ ìƒˆë¡œìš´ ì‹ ë¬¸ì‚¬ ì¶”ê°€ ë°©ë²•

### 1. ìƒˆ í¬ë¡¤ëŸ¬ í´ë˜ìŠ¤ ìƒì„±

ì˜ˆ: ì¸ì²œì¼ë³´ ì¶”ê°€í•˜ê¸°

```python
# src/crawlers/regional/seoul/incheon_ilbo.py

from base_crawler import BaseCrawler
from typing import List, Dict, Optional
from datetime import datetime

class IncheonIlboCrawler(BaseCrawler):
    """ì¸ì²œì¼ë³´ ê²½ì œì„¹ì…˜ í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        config = {
            'article_selector': 'div.news-list',
            'title_selector': 'h3.title',
            'link_selector': 'a.link',
        }
        
        super().__init__(
            newspaper_name='ì¸ì²œì¼ë³´',
            region='ì„œìš¸',  # ë˜ëŠ” 'ì¸ì²œ'
            base_url='https://www.incheon.com',
            config=config
        )
    
    def get_article_urls(self) -> List[str]:
        # URL ì¶”ì¶œ ë¡œì§
        pass
    
    def parse_article(self, url: str) -> Optional[Dict]:
        # ê¸°ì‚¬ íŒŒì‹± ë¡œì§
        pass
```

### 2. í¬ë¡¤ëŸ¬ ë§¤ë‹ˆì €ì— ë“±ë¡

```python
# src/crawlers/crawler_manager.py

from regional.seoul.incheon_ilbo import IncheonIlboCrawler

def register_all_crawlers(self):
    crawlers_list = [
        SeoulShinmunCrawler(),
        GyeonggiIlboCrawler(),
        GangwonDominIlboCrawler(),
        IncheonIlboCrawler(),  # ì¶”ê°€!
    ]
```

**ë!** ğŸ‰

## ğŸ’¡ ì£¼ì˜ì‚¬í•­

1. **CSS ì„ íƒì í™•ì¸**: ê° ì‹ ë¬¸ì‚¬ ì‚¬ì´íŠ¸ì˜ ì‹¤ì œ HTML êµ¬ì¡°ì— ë§ê²Œ ì„ íƒìë¥¼ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.
2. **í¬ë¡¤ë§ ì˜ˆì˜**: `time.sleep(0.3)`ìœ¼ë¡œ ì„œë²„ ë¶€í•˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
3. **User-Agent**: ë´‡ ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•´ User-Agentë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
4. **ì—ëŸ¬ ì²˜ë¦¬**: ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜, íƒ€ì„ì•„ì›ƒ ë“±ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•©ë‹ˆë‹¤.

## ğŸ“š ì¶”ê°€ ë¦¬ì†ŒìŠ¤

- BeautifulSoup ë¬¸ì„œ: https://www.crummy.com/software/BeautifulSoup/bs4/doc/
- Selenium ë¬¸ì„œ: https://www.selenium.dev/documentation/
- CSS ì„ íƒì ê°€ì´ë“œ: https://www.w3schools.com/cssref/css_selectors.php

## âœ¨ ê¸°ëŠ¥

- âœ… OOP ì„¤ê³„ (ìƒì†, ì¶”ìƒí™”)
- âœ… ì¬ì‚¬ìš© ê°€ëŠ¥í•œ Base í´ë˜ìŠ¤
- âœ… í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°
- âœ… ì—ëŸ¬ ì²˜ë¦¬ ë° ë¡œê¹…
- âœ… CSV ì¶œë ¥
- âœ… CLI ì¸í„°í˜ì´ìŠ¤
- âœ… ì§€ì—­ë³„/ì „ì²´ í¬ë¡¤ë§ ì„ íƒ ê°€ëŠ¥

---

**Happy Crawling! ğŸš€**
